{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Tabular Deep Learning Robustness\n",
    "\n",
    "Use <https://github.com/serval-uni-lu/tabularbench>\n",
    "\n",
    "Their standardised model and datasets are here: <https://huggingface.co/serval-uni-lu/tabularbench/tree/main>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.benchmark.benchmark import benchmark\n",
    "from tabularbench.models.tab_scaler import TabScaler\n",
    "from tabularbench.datasets.dataset_factory import get_dataset\n",
    "from tabularbench.benchmark.model_utils import load_model_and_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asabuncuoglu/Documents/PMF/red-teaming/tabularbench-test/.venv/lib/python3.9/site-packages/tabularbench/attacks/moeva/moeva.py:219: UserWarning: Pymoo is not compiled. See https://pymoo.org/installation.html#installation.\n",
      "  warnings.warn(\n",
      "/Users/asabuncuoglu/Documents/PMF/red-teaming/tabularbench-test/.venv/lib/python3.9/site-packages/tabularbench/attacks/moeva/moeva.py:222: UserWarning: Deactivating further warning.\n",
      "  warnings.warn(\"Deactivating further warning.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean accuracy: 0.6380353866104341\n",
      "Robust accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "clean_acc, robust_acc = benchmark(\n",
    "    dataset=\"LCLD\",\n",
    "    model=\"TabTr_cutmix\",\n",
    "    distance=\"L2\",\n",
    "    constraints=True,\n",
    ")\n",
    "\n",
    "print(f\"Clean accuracy: {clean_acc}\")\n",
    "print(f\"Robust accuracy: {robust_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, use the following code to load a model and evaluate it on the test set\n",
    "dataset = \"LCLD\"\n",
    "model_arch = \"stg\"\n",
    "model_training= \"default\"\n",
    "ds = get_dataset(dataset)\n",
    "metadata = ds.get_metadata(only_x=True)\n",
    "device = \"cpu\"\n",
    "scaler = TabScaler(num_scaler=\"min_max\", one_hot_encode=True)\n",
    "\n",
    "model_eval = load_model_and_weights(\n",
    "    ds.name, model_arch, model_training, metadata, scaler, device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
